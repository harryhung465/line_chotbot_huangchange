{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (simple.py, line 54)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3326\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-1-d8dbdd16b2ea>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from kafka import KafkaConsumer\n",
      "  File \u001b[1;32m\"/opt/conda/lib/python3.7/site-packages/kafka/__init__.py\"\u001b[0m, line \u001b[1;32m23\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from kafka.producer import KafkaProducer\n",
      "\u001b[0;36m  File \u001b[0;32m\"/opt/conda/lib/python3.7/site-packages/kafka/producer/__init__.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from .simple import SimpleProducer\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/opt/conda/lib/python3.7/site-packages/kafka/producer/simple.py\"\u001b[0;36m, line \u001b[0;32m54\u001b[0m\n\u001b[0;31m    return '<SimpleProducer batch=%s>' % self.async\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import sys, json, pymysql, pymongo\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 與 MongoDB連線\n",
    "    ##client = pymongo.MongoClient(host=\"mongodb\", port=27017)\n",
    "    # 指定為 test 資料庫\n",
    "    ##db = client.test\n",
    "    # 指定 temp_humidity 集合, MongoDB的每個資料庫又包含許多集合(collection), 類似於關聯性資料庫中的表\n",
    "    ##collection = db.bpm\n",
    "\n",
    "    # 設定要連線到Kafka集群的相關設定, 產生一個Kafka的Consumer的實例\n",
    "    consumer = KafkaConsumer(\n",
    "        # 指定Kafka集群伺服器\n",
    "        bootstrap_servers=[\"35.224.83.201:9092\"],\n",
    "        # ConsumerGroup的名稱, 可以不指定\n",
    "        #group_id=\"cg_001\",\n",
    "        # 指定msgKey的反序列化器, 若Key為None, 無法反序列化\n",
    "        # key_deserializer=bytes.decode,\n",
    "        # 指定msgValue的反序列化器\n",
    "        #value_deserializer=bytes.decode,\n",
    "#         value_deserializer=lambda m: json.loads(m.decode('ascii')),\n",
    "        # 是否從這個ConsumerGroup尚未讀取的partition / offset開始讀\n",
    "        auto_offset_reset=\"earliest\",\n",
    "    )\n",
    "   \n",
    "    # 讓Consumer向Kafka集群訂閱指定的topic\n",
    "    consumer.subscribe(topics=\"qqq\")\n",
    "    \n",
    "    # 持續的拉取Kafka有進來的訊息\n",
    "    try:\n",
    "        print(\"Now listening for incoming messages ...\")\n",
    "        # 持續監控是否有新的record進來\n",
    "        for record in consumer:\n",
    "            topic = record.topic\n",
    "            partition = record.partition\n",
    "            offset = record.offset\n",
    "            timestamp = record.timestamp\n",
    "            # 取出msgKey與msgValue\n",
    "            msgKey = record.key\n",
    "            msgValue = record.value\n",
    "            # 秀出metadata與msgKey & msgValue訊息\n",
    "            print(\"topic=%s, partition=%s, offset=%s : (key=%s, value=%s)\" % (record.topic, record.partition, \n",
    "                                                                              record.offset, record.key, record.value))\n",
    "#             j = {\"device_id\": msgValue[\"device_id\"], \"timestamp\": msgValue[\"timestamp\"], \n",
    "#                   \"bpm\": msgValue[\"bpm\"]}\n",
    "#             print(\"json=\",  j)\n",
    "            \n",
    "            # 將資料存入 mongodb\n",
    "            # 存入單筆\n",
    "            ##result = collection.insert_one(j)\n",
    "            # 存入多筆\n",
    "            ##result = collection.insert_many()\n",
    "            #print(result)\n",
    "\n",
    "    except:\n",
    "        # 錯誤處理\n",
    "        e_type, e_value, e_traceback = sys.exc_info()\n",
    "        print(\"type ==> %s\" % (e_type))\n",
    "        print(\"value ==> %s\" % (e_value))\n",
    "        print(\"traceback ==> file name: %s\" % (e_traceback.tb_frame.f_code.co_filename))\n",
    "        print(\"traceback ==> line no: %s\" % (e_traceback.tb_lineno))\n",
    "        print(\"traceback ==> function name: %s\" % (e_traceback.tb_frame.f_code.co_name))\n",
    "    finally:\n",
    "        consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elasticsearch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9dd0747e41aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0melasticsearch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElasticsearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElasticsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elasticsearch:9200'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m doc = {\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'elasticsearch'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch(['elasticsearch:9200'])\n",
    "\n",
    "doc = {\n",
    "    'author': 'kimchy',\n",
    "    'text': 'Elasticsearch: cool. bonsai cool.',\n",
    "    'timestamp': datetime.now(),\n",
    "}\n",
    "res = es.index(index=\"test-index\", doc_type='tweet', id=1, body=doc)\n",
    "print(res['result'])\n",
    "\n",
    "res = es.get(index=\"test-index\", doc_type='tweet', id=1)\n",
    "print(res['_source'])\n",
    "\n",
    "es.indices.refresh(index=\"test-index\")\n",
    "\n",
    "res = es.search(index=\"test-index\", body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Got %d Hits:\" % res['hits']['total'])\n",
    "for hit in res['hits']['hits']:\n",
    "    print(\"%(timestamp)s %(author)s: %(text)s\" % hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(\"elasticsearch:9200\")\n",
    "\n",
    "es.index(index=\"test-index\", doc_type='tweet', id=1, body={\n",
    "  \"name\": \"Karl\",\n",
    "  \"email\": \"karl@gmail.com\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
